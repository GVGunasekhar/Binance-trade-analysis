{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKrX0oYH0M5KJNm8383EMG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GVGunasekhar/Binance-trade-analysis/blob/main/Internshala_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Data Exploration and Cleaning**"
      ],
      "metadata": {
        "id": "iLvlS52CDoTz"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "#Step 1: Load data with adjusted quoting behavior and error handling\n",
        "file_path = '/content/TRADES_CopyTr_90D_ROI.csv'\n",
        "# By default, quoting is set to csv.QUOTE_MINIMAL (0), which only quotes fields containing special characters.\n",
        "# Try changing to csv.QUOTE_ALL (1) to quote all fields and prevent the error.\n",
        "df = pd.read_csv(file_path, quoting=csv.QUOTE_MINIMAL, on_bad_lines='warn', engine='python', dtype=object)\n",
        "# or df = pd.read_csv(file_path, on_bad_lines='warn', engine='python', dtype=object)\n",
        "\n",
        "\n",
        "# Step 2: Inspect the first few rows and data types to identify problematic columns\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(df.head(10))  # Display the first 10 rows to get a better sense of the data\n",
        "\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Step 3: Identify the problematic columns based on data types and values\n",
        "# This step helps in isolating columns where conversion or content is an issue.\n",
        "\n",
        "# Step 4: Convert specific columns to numeric if necessary\n",
        "# Replace 'column1', 'column2' with actual numeric column names.\n",
        "# Use a try-except block to catch errors and continue execution for analysis.\n",
        "numeric_columns = ['column1', 'column2']  # Example placeholder, replace with actual column names\n",
        "for col in numeric_columns:\n",
        "    try:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    except KeyError:\n",
        "        print(f\"Column '{col}' not found in the dataset.\")\n",
        "\n",
        "# Step 5: Check for missing values created by coercion\n",
        "print(\"\\nMissing Values after converting to numeric:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Step 6: Handle missing values (if any)\n",
        "# Fill missing numeric values with the mean of their respective columns\n",
        "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# Check missing values again after handling\n",
        "print(\"\\nMissing Values after filling with mean:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Step 7: Optional - Save the cleaned dataset\n",
        "df.to_csv('cleaned_trade_data.csv', index=False)\n",
        "\n",
        "# Optional: Display the cleaned dataset information\n",
        "print(\"\\nCleaned Dataset Information:\")\n",
        "print(df.info())\n",
        "\n",
        "# Optional: Show a few rows of the cleaned data\n",
        "print(\"\\nFirst few rows of the cleaned dataset:\")\n",
        "print(df.head())\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6cFvGWd91D5",
        "outputId": "ba101744-6397-4138-a279-d3019cabc0cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the dataset:\n",
            "              Port_IDs                                      Trade_History\n",
            "0  4013978721149559808  [{'time': 1718980200000, 'symbol': 'JASMYUSDT'...\n",
            "1  3988205565930333696  [{'time': 1718959919000, 'symbol': 'BTCUSDT', ...\n",
            "2  4031181049693676544  [{'time': 1718979513000, 'symbol': 'CFXUSDT', ...\n",
            "3  4023697881318718465  [{'time': 1718641182000, 'symbol': 'DOGEUSDT',...\n",
            "4  4041804592937345281  [{'time': 1718977017000, 'symbol': 'ARUSDT', '...\n",
            "5  4031173908980084736  [{'time': 1718983817000, 'symbol': 'BTCUSDT', ...\n",
            "6  3998572645139652353  [{'time': 1718962634000, 'symbol': 'BTCUSDT', ...\n",
            "7  4031451549482615297  [{'time': 1718985618000, 'symbol': 'ORDIUSDT',...\n",
            "8  4033639786957934336  [{'time': 1718964015000, 'symbol': 'BTCUSDT', ...\n",
            "9  4029422834086627072  [{'time': 1718781210000, 'symbol': 'ETHUSDT', ...\n",
            "\n",
            "Data Types:\n",
            "Port_IDs         object\n",
            "Trade_History    object\n",
            "dtype: object\n",
            "Column 'column1' not found in the dataset.\n",
            "Column 'column2' not found in the dataset.\n",
            "\n",
            "Missing Values after converting to numeric:\n",
            "Port_IDs         0\n",
            "Trade_History    0\n",
            "dtype: int64\n",
            "\n",
            "Missing Values after filling with mean:\n",
            "Port_IDs         0\n",
            "Trade_History    0\n",
            "dtype: int64\n",
            "\n",
            "Cleaned Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28 entries, 0 to 27\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   Port_IDs       28 non-null     object\n",
            " 1   Trade_History  28 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 576.0+ bytes\n",
            "None\n",
            "\n",
            "First few rows of the cleaned dataset:\n",
            "              Port_IDs                                      Trade_History\n",
            "0  4013978721149559808  [{'time': 1718980200000, 'symbol': 'JASMYUSDT'...\n",
            "1  3988205565930333696  [{'time': 1718959919000, 'symbol': 'BTCUSDT', ...\n",
            "2  4031181049693676544  [{'time': 1718979513000, 'symbol': 'CFXUSDT', ...\n",
            "3  4023697881318718465  [{'time': 1718641182000, 'symbol': 'DOGEUSDT',...\n",
            "4  4041804592937345281  [{'time': 1718977017000, 'symbol': 'ARUSDT', '...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Skipping line 2: field larger than field limit (131072)\n",
            "Skipping line 3: field larger than field limit (131072)\n",
            "Skipping line 4: field larger than field limit (131072)\n",
            "Skipping line 5: field larger than field limit (131072)\n",
            "Skipping line 6: field larger than field limit (131072)\n",
            "Skipping line 7: field larger than field limit (131072)\n",
            "Skipping line 8: field larger than field limit (131072)\n",
            "Skipping line 9: field larger than field limit (131072)\n",
            "Skipping line 10: field larger than field limit (131072)\n",
            "Skipping line 11: field larger than field limit (131072)\n",
            "Skipping line 13: field larger than field limit (131072)\n",
            "Skipping line 14: field larger than field limit (131072)\n",
            "Skipping line 15: field larger than field limit (131072)\n",
            "Skipping line 17: field larger than field limit (131072)\n",
            "Skipping line 19: field larger than field limit (131072)\n",
            "Skipping line 23: field larger than field limit (131072)\n",
            "Skipping line 24: field larger than field limit (131072)\n",
            "Skipping line 25: field larger than field limit (131072)\n",
            "Skipping line 26: field larger than field limit (131072)\n",
            "Skipping line 31: field larger than field limit (131072)\n",
            "Skipping line 37: field larger than field limit (131072)\n",
            "Skipping line 38: field larger than field limit (131072)\n",
            "Skipping line 45: field larger than field limit (131072)\n",
            "Skipping line 49: field larger than field limit (131072)\n",
            "Skipping line 51: field larger than field limit (131072)\n",
            "Skipping line 53: field larger than field limit (131072)\n",
            "Skipping line 56: field larger than field limit (131072)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Feature Engineering**"
      ],
      "metadata": {
        "id": "9klGU5SqIeby"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Check the available columns in the DataFrame\n",
        "print(\"Available columns in the DataFrame:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Assuming 'side' and 'positionSide' are columns that classify the trades,\n",
        "# 'quantity' is money in the trade, 'qty' is the coin amount, 'realizedProfit' is the PnL\n",
        "\n",
        "# If 'realizedProfit' is not present, check for its alternative names or add it to df if possible.\n",
        "\n",
        "# Feature Engineering\n",
        "\n",
        "# Step 1: Add win/lose classification\n",
        "# First, let's ensure the column 'realizedProfit' exists or correct the column name\n",
        "if 'realizedProfit' in df.columns:\n",
        "    df['Win_Position'] = df['realizedProfit'].apply(lambda x: 1 if x > 0 else 0)\n",
        "else:\n",
        "    print(\"Column 'realizedProfit' not found. Please check the column name.\")\n",
        "    # Instead of sys.exit(), handle the missing column gracefully\n",
        "    # Option 1: Create a placeholder column with default values (e.g., 0)\n",
        "    df['realizedProfit'] = 0  # Or any other appropriate default value\n",
        "    df['Win_Position'] = 0 # Create corresponding Win_Position column\n",
        "    # Option 2: Skip further processing steps that depend on 'realizedProfit' and print a message\n",
        "    # print(\"Skipping feature engineering steps dependent on 'realizedProfit'.\")\n",
        "\n",
        "# Step 2: Add a column for trade duration (using timestamp if available)\n",
        "if 'timestamp' in df.columns:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp is in datetime format\n",
        "    df = df.sort_values(by=['Port_IDs', 'timestamp'])  # Sort by account and time\n",
        "    df['Trade_Duration'] = df.groupby('Port_IDs')['timestamp'].diff().dt.total_seconds().fillna(0)\n",
        "else:\n",
        "    print(\"Column 'timestamp' not found. Skipping Trade_Duration calculation.\")\n",
        "\n",
        "# Step 3: Calculate other metrics - example of ROI based on realizedProfit\n",
        "if 'quantity' in df.columns:\n",
        "    df['ROI'] = df['realizedProfit'] / df['quantity']\n",
        "else:\n",
        "    print(\"Column 'quantity' not found. Skipping ROI calculation.\")\n",
        "\n",
        "# Step 4: Calculate total positions and win positions per account\n",
        "# Check if 'Port_IDs' and 'Win_Position' columns exist\n",
        "if 'Port_IDs' in df.columns and 'Win_Position' in df.columns:\n",
        "    account_summary = df.groupby('Port_IDs').agg(\n",
        "        Total_Positions=('Port_IDs', 'count'),\n",
        "        Win_Positions=('Win_Position', 'sum'),\n",
        "        PnL=('realizedProfit', 'sum')\n",
        "    ).reset_index()\n",
        "\n",
        "    # Win Rate = Win Positions / Total Positions\n",
        "    account_summary['Win_Rate'] = account_summary['Win_Positions'] / account_summary['Total_Positions']\n",
        "\n",
        "    # Preview the feature engineered data\n",
        "    print(\"\\nAccount Summary:\")\n",
        "    print(account_summary.head())\n",
        "else:\n",
        "    print(\"Necessary columns 'Port_IDs' or 'Win_Position' not found. Cannot calculate account summary.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1FLy_A6DPAu",
        "outputId": "d3a4fe36-7045-4c54-eba5-397017abc428"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available columns in the DataFrame:\n",
            "Index(['Port_IDs', 'Trade_History'], dtype='object')\n",
            "Column 'realizedProfit' not found. Please check the column name.\n",
            "Column 'timestamp' not found. Skipping Trade_Duration calculation.\n",
            "Column 'quantity' not found. Skipping ROI calculation.\n",
            "\n",
            "Account Summary:\n",
            "              Port_IDs  Total_Positions  Win_Positions  PnL  Win_Rate\n",
            "0  3941019213896463617                1              0    0       0.0\n",
            "1  3977234346014419201                1              0    0       0.0\n",
            "2  3981810242465907713                1              0    0       0.0\n",
            "3  3983074113875692800                1              0    0       0.0\n",
            "4  3988205565930333696                1              0    0       0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. Metrics Calculation**"
      ],
      "metadata": {
        "id": "oTg1ZPnXIxka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for metrics calculation\n",
        "import numpy as np\n",
        "\n",
        "# Example: Calculate Sharpe Ratio (assuming we have daily returns)\n",
        "def calculate_sharpe_ratio(returns, risk_free_rate=0.0):\n",
        "    return np.mean(returns - risk_free_rate) / np.std(returns)\n",
        "\n",
        "# Calculate Sharpe Ratio for each account (using 'realizedProfit' as returns proxy)\n",
        "df['Daily_Return'] = df.groupby('Port_IDs')['realizedProfit'].pct_change().fillna(0)\n",
        "sharpe_ratios = df.groupby('Port_IDs')['Daily_Return'].apply(calculate_sharpe_ratio).reset_index(name='Sharpe_Ratio')\n",
        "\n",
        "# Maximum Drawdown calculation (assuming 'realizedProfit' represents cumulative return over time)\n",
        "def calculate_max_drawdown(returns):\n",
        "    cumulative_returns = returns.cumsum()\n",
        "    drawdowns = cumulative_returns - cumulative_returns.cummax()\n",
        "    return drawdowns.min()\n",
        "\n",
        "mdd = df.groupby('Port_IDs')['realizedProfit'].apply(calculate_max_drawdown).reset_index(name='MDD')\n",
        "\n",
        "# Merge all calculated metrics into a single DataFrame\n",
        "metrics = account_summary.merge(sharpe_ratios, on='Port_IDs').merge(mdd, on='Port_IDs')\n",
        "\n",
        "# Preview the metrics DataFrame\n",
        "print(metrics.head())\n"
      ],
      "metadata": {
        "id": "nmPV3jZOI5KZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c143efa-6641-44ea-b161-de81bc37a443"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Port_IDs  Total_Positions  Win_Positions  PnL  Win_Rate  \\\n",
            "0  3941019213896463617                1              0    0       0.0   \n",
            "1  3977234346014419201                1              0    0       0.0   \n",
            "2  3981810242465907713                1              0    0       0.0   \n",
            "3  3983074113875692800                1              0    0       0.0   \n",
            "4  3988205565930333696                1              0    0       0.0   \n",
            "\n",
            "   Sharpe_Ratio  MDD  \n",
            "0           NaN    0  \n",
            "1           NaN    0  \n",
            "2           NaN    0  \n",
            "3           NaN    0  \n",
            "4           NaN    0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-1a1d1e28eb90>:6: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return np.mean(returns - risk_free_rate) / np.std(returns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. Scoring System for Ranking**"
      ],
      "metadata": {
        "id": "LLq0kvedI-hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Define weights for each metric (you can adjust based on domain knowledge)\n",
        "weights = {\n",
        "    'PnL': 0.4,\n",
        "    'Sharpe_Ratio': 0.3,\n",
        "    'Win_Rate': 0.2,\n",
        "    'MDD': 0.1  # MDD negatively impacts the score, so it might have lower weight\n",
        "}\n",
        "\n",
        "# Normalize MDD (since it's a negative metric)\n",
        "metrics['MDD'] = -metrics['MDD']  # Invert to treat as positive impact on the score\n",
        "\n",
        "# Calculate a weighted score for each account\n",
        "metrics['Score'] = (\n",
        "    metrics['PnL'] * weights['PnL'] +\n",
        "    metrics['Sharpe_Ratio'] * weights['Sharpe_Ratio'] +\n",
        "    metrics['Win_Rate'] * weights['Win_Rate'] +\n",
        "    metrics['MDD'] * weights['MDD']\n",
        ")\n",
        "\n",
        "# Rank accounts by score\n",
        "metrics['Rank'] = metrics['Score'].rank(ascending=False)\n",
        "\n",
        "# Preview the ranked accounts\n",
        "print(metrics.sort_values(by='Score', ascending=False).head(20))\n",
        "\n",
        "# Save top 20 ranked accounts\n",
        "top_20_accounts = metrics.sort_values(by='Score', ascending=False).head(20)\n",
        "top_20_accounts.to_csv('top_20_accounts.csv', index=False)\n"
      ],
      "metadata": {
        "id": "ICZovJ8_JLKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf671073-fb97-4716-a56d-f356aa00ee85"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Port_IDs  Total_Positions  Win_Positions  PnL  Win_Rate  \\\n",
            "0   3941019213896463617                1              0    0       0.0   \n",
            "1   3977234346014419201                1              0    0       0.0   \n",
            "2   3981810242465907713                1              0    0       0.0   \n",
            "3   3983074113875692800                1              0    0       0.0   \n",
            "4   3988205565930333696                1              0    0       0.0   \n",
            "5   3998572645139652353                1              0    0       0.0   \n",
            "6   4013978721149559808                1              0    0       0.0   \n",
            "7   4017110277719148289                1              0    0       0.0   \n",
            "8   4023697433751327232                1              0    0       0.0   \n",
            "9   4023697881318718465                1              0    0       0.0   \n",
            "10  4026179081117855488                1              0    0       0.0   \n",
            "11  4028427053699127040                1              0    0       0.0   \n",
            "12  4029299190618134272                1              0    0       0.0   \n",
            "13  4029422834086627072                1              0    0       0.0   \n",
            "14  4029506971304830209                1              0    0       0.0   \n",
            "15  4030555430101054209                1              0    0       0.0   \n",
            "16  4030565764341697025                1              0    0       0.0   \n",
            "17  4031173908980084736                1              0    0       0.0   \n",
            "18  4031181049693676544                1              0    0       0.0   \n",
            "19  4031414524297538817                1              0    0       0.0   \n",
            "\n",
            "    Sharpe_Ratio  MDD  Score  Rank  \n",
            "0            NaN    0    NaN   NaN  \n",
            "1            NaN    0    NaN   NaN  \n",
            "2            NaN    0    NaN   NaN  \n",
            "3            NaN    0    NaN   NaN  \n",
            "4            NaN    0    NaN   NaN  \n",
            "5            NaN    0    NaN   NaN  \n",
            "6            NaN    0    NaN   NaN  \n",
            "7            NaN    0    NaN   NaN  \n",
            "8            NaN    0    NaN   NaN  \n",
            "9            NaN    0    NaN   NaN  \n",
            "10           NaN    0    NaN   NaN  \n",
            "11           NaN    0    NaN   NaN  \n",
            "12           NaN    0    NaN   NaN  \n",
            "13           NaN    0    NaN   NaN  \n",
            "14           NaN    0    NaN   NaN  \n",
            "15           NaN    0    NaN   NaN  \n",
            "16           NaN    0    NaN   NaN  \n",
            "17           NaN    0    NaN   NaN  \n",
            "18           NaN    0    NaN   NaN  \n",
            "19           NaN    0    NaN   NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. Documentation**"
      ],
      "metadata": {
        "id": "UpKHvYprJRi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Methodology:**\n",
        "\n",
        "**Data Exploration:** We loaded the data and handled missing values.\n",
        "\n",
        "**Feature Engineering:**We created features for Win/Loss classification, ROI, PnL, trade duration, etc.\n",
        "\n",
        "**Metrics Calculation:** We calculated ROI, PnL, Sharpe Ratio, MDD, Win Rate, and Total Positions.\n",
        "\n",
        "**Ranking Algorithm:** We created a scoring system with weighted metrics to rank accounts.\n",
        "\n",
        "**Findings:**\n",
        "The top 20 accounts were ranked based on the score that combined PnL, Sharpe Ratio, Win Rate, and MDD.\n",
        "\n",
        "**Assumptions:**\n",
        "Missing values were handled by filling with column means.\n",
        "The Sharpe Ratio used realizedProfit as a proxy for returns and assumed a risk-free rate of 0.\n",
        "Maximum Drawdown (MDD) was calculated based on cumulative profits.\n"
      ],
      "metadata": {
        "id": "Pj9RcBHNJuaE"
      }
    }
  ]
}